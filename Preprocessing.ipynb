{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image, ImageFilter, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [cv2.imread(file) for file in glob.glob(\"C:/Users/devda/Major/Data/all-mias/JPEG/Raw/*.jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Grayscale\n",
    "for i in range(322):\n",
    "    images[i] = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thresholding\n",
    "ret = [0] * 322\n",
    "thresh = [0] * 322\n",
    "for i in range(322):\n",
    "    ret[i], thresh[i] = cv2.threshold(images[i],15,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting largest region\n",
    "new_img = [0] * 322\n",
    "for i in range(322):\n",
    "    new_img[i] = np.zeros_like(thresh[i])                                        \n",
    "    for val in np.unique(thresh[i])[1:]:                                      \n",
    "        mask = np.uint8(thresh[i] == val)                                     \n",
    "        labels, stats = cv2.connectedComponentsWithStats(mask, 4)[1:3]  \n",
    "        largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])      \n",
    "        new_img[i][labels == largest_label] = val                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing background\n",
    "for i in range(322):\n",
    "    for j in range(len(new_img[i])):\n",
    "        for k in range(len(new_img[i])):\n",
    "            if new_img[i][j, k] == 0:\n",
    "                images[i][j, k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean filter\n",
    "for i in range(322):\n",
    "    fig_size=3\n",
    "    images[i] = cv2.blur(images[i],(fig_size, fig_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contrast enhancement - histogram equalisation\n",
    "for i in range(322):\n",
    "    images[i] = cv2.equalizeHist(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving files\n",
    "os.mkdir('Preprocessed')\n",
    "for i in range(322):\n",
    "    cv2.imwrite(\"Preprocessed/Image%03i.jpg\" %(i+1), images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing session\n",
    "import dill\n",
    "dill.dump_session('Preprocessing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
